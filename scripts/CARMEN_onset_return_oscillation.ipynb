{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the parameters before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CARMEN Trace Analysis Script â€“ Onset, Return, and Oscillation Detection\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "This script performs post-processing of calcium multiplexing data exported from the CARMEN Fiji macro and \n",
    "post processed with CARMEN_combine_and_curvefitting_xlsmtemplate.ipynb .\n",
    "\n",
    "For each input Excel file (.xlsm), the script:\n",
    "- Loads time series and fluorescence intensity data.\n",
    "- Applies Savitzky-Golay smoothing to reduce noise in signal traces.\n",
    "- Calculates the first derivative of each smoothed trace to identify activation onset times.\n",
    "- Defines a baseline region and calculates the time taken for the signal to return to baseline.\n",
    "- Detects oscillations (peaks and troughs) between onset and return.\n",
    "- Plots raw, smoothed, and derivative traces for visual inspection, highlighting key features.\n",
    "\n",
    "Key Features:\n",
    "- Derivative-based onset detection using `scipy.signal.find_peaks`, adjustable for signal polarity.\n",
    "- Baseline return detection using threshold-based criteria with configurable tolerance and duration.\n",
    "- Detection of oscillations between onset and return using prominence-based peak/trough filtering.\n",
    "- High-resolution visualisation of signal features across time.\n",
    "\n",
    "Assumptions:\n",
    "- Input files are `.xlsm` Excel workbooks with a sheet named 'Time Analysis'.\n",
    "- Time is stored in the column named 'Protocol Time [sec]'.\n",
    "- Signal data are found in columns C, D, and E (representing GFP, RFP, and NIR).\n",
    "- Signals are ordered consistently across files, and rows with NaN values are excluded automatically.\n",
    "\n",
    "Usage:\n",
    "- Set `folder_path` to the directory containing your input `.xlsm` files.\n",
    "- Adjust analysis parameters at the top of the script to suit your experimental design.\n",
    "- Run the script in a Python environment with the required dependencies.\n",
    "\n",
    "Output:\n",
    "- Printed console summaries of detected onset, return, and duration per signal.\n",
    "- Matplotlib plots showing raw, smoothed, and derivative signals with annotated onsets and returns.\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "\n",
    "# === USER PARAMETERS === #\n",
    "\n",
    "# Smoothing constants for Savitzky-Golay filter\n",
    "window_length = 15 # must be an odd number\n",
    "polyorder = 2 # polynomial order for smoothing\n",
    "window_length_strong = 15\n",
    "polyorder_strong = 2\n",
    "\n",
    "# Return to baseline detection sensitivity\n",
    "threshold_percentage = 0.3 # how close to baseline the signal must return\n",
    "min_consecutive_points = 15 # number of points within the threshold to confirm return\n",
    "\n",
    "# Baseline definition window (in seconds) \n",
    "baseline_start_time = 200\n",
    "baseline_end_time = 320\n",
    "\n",
    "# Define peak direction per signal: +1 = looking for peaks, -1 = looking for troughs\n",
    "gfp_peak_or_trough = +1  # GFP signal is positive (looking for peaks)\n",
    "rfp_peak_or_trough = -1  # RFP signal is negative (looking for troughs)\n",
    "nir_peak_or_trough = +1  # NIR signal is positive (looking for peaks)\n",
    "\n",
    "# Peak detection settings for onset (derivative-based)\n",
    "gfp_params = {'height': 0.03, 'distance': 5, 'prominence': 0.2, 'width': 5}  # GFP derivative onset peak detection\n",
    "rfp_params = {'height': 0.02, 'distance': 5, 'prominence': 0.2, 'width': 3}  # RFP derivative onset peak detection\n",
    "nir_params = {'height': 0.02, 'distance': 5, 'prominence': 0.4, 'width': 5}  # NIR derivative onset peak detection\n",
    "\n",
    "# Peak detection settings for oscillations (raw signals)\n",
    "gfp_peak_prominence = 0.3\n",
    "gfp_peak_distance = 5\n",
    "rfp_peak_prominence = 0.3\n",
    "rfp_peak_distance = 5\n",
    "nir_peak_prominence = 0.3\n",
    "nir_peak_distance = 5\n",
    "\n",
    "# X-axis zoom range for plotting to focus on the specified range in seconds\n",
    "zoomed_min = 320 \n",
    "zoomed_max = 450\n",
    "\n",
    "# === INPUT DATA FOLDER === #\n",
    "folder_path = r\"your\\file\\path\" \n",
    "file_list = [file for file in os.listdir(folder_path) if file.endswith('.xlsm')]\n",
    "\n",
    "if not file_list:\n",
    "    print(f\"No '.xlsm' files found in the folder: {folder_path}\")\n",
    "else:\n",
    "    print(f\"Found {len(file_list)} files: {file_list}\")\n",
    "\n",
    "# === PROCESS EACH FILE === #\n",
    "for file_name in file_list:\n",
    "    print(f\"Processing file: {file_name}\") \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # Load data from Excel\n",
    "    df = pd.read_excel(file_path, sheet_name='Time Analysis')\n",
    "    \n",
    "    # Load time in seconds from column B\n",
    "    time_seconds = df['Protocol Time [sec]'].to_numpy()\n",
    "    \n",
    "    data_sets = []  # To store data sets for the current file\n",
    "    results = []  # To store the results for the current file\n",
    "\n",
    "    # Load intensity data from columns C-D-E, F-G-H, etc.\n",
    "    intensity_set = df.iloc[:, 2:5].to_numpy()  # Extract columns C-D-E\n",
    "    \n",
    "    # Filter intensity data and time; Handle NaN values\n",
    "    mask = ~np.isnan(intensity_set).any(axis=1)  # Mask to filter out rows with NaN values\n",
    "    filtered_time = time_seconds[mask]           # Filter time values\n",
    "    filtered_intensity = intensity_set[mask]     # Filter intensity values\n",
    "        \n",
    "    if len(filtered_intensity) > 0:  # Check if the intensity data is not empty\n",
    "        data_sets.append((filtered_time, filtered_intensity))\n",
    "\n",
    "    # Analyze each data set for the current file\n",
    "    for idx, (time, intensity) in enumerate(data_sets):\n",
    "        print(f\"  Processing dataset {idx + 1} in file: {file_name}\")\n",
    "        gfp, rfp, nir = intensity.T  # Split intensity data into gfp, rfp, and nir\n",
    "        \n",
    "        # Step 1: Smooth the data using with Savitzky-Golay filter\n",
    "        gfp_smooth = savgol_filter(gfp, window_length, polyorder)\n",
    "        rfp_smooth = savgol_filter(rfp, window_length, polyorder)\n",
    "        nir_smooth = savgol_filter(nir, window_length, polyorder)\n",
    "        \n",
    "        # Stronger smoothing (for return-to-baseline analysis)          \n",
    "        gfp_smooth_strong = savgol_filter(gfp, window_length=window_length_strong, polyorder=polyorder_strong)\n",
    "        rfp_smooth_strong = savgol_filter(rfp, window_length=window_length_strong, polyorder=polyorder_strong)\n",
    "        nir_smooth_strong = savgol_filter(nir, window_length=window_length_strong, polyorder=polyorder_strong)\n",
    "\n",
    "        # Step 2: Compute derivatives to detect onsets\n",
    "        gfp_derivative = np.gradient(gfp_smooth, time)\n",
    "        rfp_derivative = np.gradient(rfp_smooth, time)\n",
    "        nir_derivative = np.gradient(nir_smooth, time)\n",
    "        \n",
    "        # Step 3: Detect onset times\n",
    "        # Multiply the derivatives by the respective direction\n",
    "        gfp_adjusted_derivative = gfp_peak_or_trough * gfp_derivative\n",
    "        rfp_adjusted_derivative = rfp_peak_or_trough * rfp_derivative\n",
    "        nir_adjusted_derivative = nir_peak_or_trough * nir_derivative\n",
    "        #Detect peaks in the derivative\n",
    "        gfp_peaks_derivative, _ = find_peaks(gfp_adjusted_derivative, **gfp_params)\n",
    "        rfp_peaks_derivative, _ = find_peaks(rfp_adjusted_derivative, **rfp_params)\n",
    "        nir_peaks_derivative, _ = find_peaks(nir_adjusted_derivative, **nir_params)\n",
    "        # Assign onset times if peaks or troughs were detected        \n",
    "        gfp_onset_time = time[gfp_peaks_derivative[0]] if len(gfp_peaks_derivative) > 0 else None\n",
    "        rfp_onset_time = time[rfp_peaks_derivative[0]] if len(rfp_peaks_derivative) > 0 else None\n",
    "        nir_onset_time = time[nir_peaks_derivative[0]] if len(nir_peaks_derivative) > 0 else None\n",
    "        \n",
    "        # Step 4: Compute return time and global durations\n",
    "                \n",
    "        # Function to define the baseline from a specific time range\n",
    "        def define_baseline(signal, time, baseline_start_time, baseline_end_time):\n",
    "            # Find the indices corresponding to the specified time range\n",
    "            baseline_indices = np.where((time >= baseline_start_time) & (time <= baseline_end_time))[0]\n",
    "\n",
    "            # Ensure that valid indices were found\n",
    "            if len(baseline_indices) == 0:\n",
    "                raise ValueError(\"No valid indices found for baseline calculation.\")\n",
    "            \n",
    "            # Ensure the start time is before the end time\n",
    "            if baseline_start_time >= baseline_end_time:\n",
    "                raise ValueError(\"Baseline start time should be less than baseline end time.\")\n",
    "            \n",
    "            # Check if indices are within the bounds of the signal\n",
    "            if max(baseline_indices) >= len(signal):\n",
    "                raise IndexError(\"Baseline indices are out of bounds of the signal length.\")\n",
    "            \n",
    "            # Calculate and return the mean of the specified baseline range\n",
    "            return np.mean(signal[baseline_indices])\n",
    "        \n",
    "        # Function to calculate signal duration from onset to baseline return\n",
    "        def calculate_signal_duration(time, smoothed_signal, baseline, onset_time, signal_type, \n",
    "                                    is_low_baseline, min_consecutive_points=min_consecutive_points, \n",
    "                                    threshold_percentage=threshold_percentage):    \n",
    "            # Handle the case where onset_time is None, e.g., no onset time could be identified automatically\n",
    "            onset_time_candidate = onset_time\n",
    "            if onset_time_candidate is None:\n",
    "                print(f\"{signal_type} onset_time is None. Using a fixed value of 60 seconds.\")\n",
    "                onset_time_candidate = 360  # Assign default onset_time\n",
    "\n",
    "            # Find the onset index using a tolerance to match the onset time\n",
    "            onset_index = (np.abs(time - onset_time_candidate)).argmin()\n",
    "\n",
    "            # Start searching for the return to baseline at least 30 data points after the onset\n",
    "            start_search_index = onset_index + 30\n",
    "\n",
    "            # Define the lower and upper threshold based on the threshold percentage of the baseline\n",
    "            lower_threshold = baseline * (1 - threshold_percentage)\n",
    "            upper_threshold = baseline * (1 + threshold_percentage)\n",
    "\n",
    "            # Initialize variables to track consecutive points within threshold\n",
    "            consecutive_points = 0\n",
    "            tracked_value_idx = None\n",
    "\n",
    "            # Loop through the signal after the onset to find where the signal returns to baseline range\n",
    "            for idx in range(start_search_index, len(smoothed_signal)):\n",
    "                # Check if the signal is within the range of lower and upper thresholds\n",
    "                if lower_threshold <= smoothed_signal[idx] <= upper_threshold:\n",
    "                    consecutive_points += 1\n",
    "\n",
    "                    # Track maximum or minimum value within the valid range based on `is_low_baseline`\n",
    "                    if is_low_baseline:\n",
    "                        # For GFP and NIR: Track minimum value\n",
    "                        if tracked_value_idx is None or smoothed_signal[idx] < smoothed_signal[tracked_value_idx]:\n",
    "                            tracked_value_idx = idx\n",
    "                    else:\n",
    "                        # For RFP: Track maximum value\n",
    "                        if tracked_value_idx is None or smoothed_signal[idx] > smoothed_signal[tracked_value_idx]:\n",
    "                            tracked_value_idx = idx\n",
    "\n",
    "                else:\n",
    "                    # Reset the consecutive points count if the signal leaves the threshold range\n",
    "                    consecutive_points = 0\n",
    "                    tracked_value_idx = None\n",
    "\n",
    "                # If enough consecutive points are found, consider this a valid return to baseline\n",
    "                if consecutive_points >= min_consecutive_points:\n",
    "                    break  # Exit the loop once a valid return to baseline is found\n",
    "\n",
    "            # Determine return time based on the tracked max or min value index\n",
    "            if tracked_value_idx is not None:\n",
    "                return_time = time[tracked_value_idx]\n",
    "            else:\n",
    "                return_time = np.nan  # If no valid return indices were found\n",
    "\n",
    "            # Calculate the duration from onset to the return to baseline\n",
    "            duration = return_time - onset_time_candidate\n",
    "\n",
    "            # Return the onset time, return time, and calculated duration\n",
    "            return onset_time_candidate, return_time, duration\n",
    "\n",
    "        # Calculate baselines\n",
    "        gfp_baseline = define_baseline(gfp, time, baseline_start_time, baseline_end_time)\n",
    "        print(f\"GFP baseline calculated for the range {baseline_start_time}s to {baseline_end_time}s: {gfp_baseline}\")\n",
    "\n",
    "        nir_baseline = define_baseline(nir, time, baseline_start_time, baseline_end_time)\n",
    "        print(f\"NIR baseline calculated for the range {baseline_start_time}s to {baseline_end_time}s: {nir_baseline}\")\n",
    "\n",
    "        rfp_baseline = define_baseline(rfp, time, baseline_start_time, baseline_end_time)\n",
    "        print(f\"RFP baseline calculated for the range {baseline_start_time}s to {baseline_end_time}s: {rfp_baseline}\")\n",
    "\n",
    "        # Determine if the baseline is low or high for each signal\n",
    "        low_baseline_threshold = 20\n",
    "        is_low_baseline_gfp = gfp_baseline < low_baseline_threshold\n",
    "        is_low_baseline_nir = nir_baseline < low_baseline_threshold\n",
    "        is_low_baseline_rfp = rfp_baseline < low_baseline_threshold\n",
    "\n",
    "        # Calculate durations for GFP, RFP, and NIR\n",
    "        # GFP: Determine if it's a low baseline and calculate return time accordingly\n",
    "        gfp_onset_time, gfp_return, gfp_globalduration = calculate_signal_duration(\n",
    "            time, gfp_smooth_strong, gfp_baseline, gfp_onset_time, signal_type='GFP', is_low_baseline=is_low_baseline_gfp)\n",
    "\n",
    "        # NIR: Determine if it's a low baseline and calculate return time accordingly\n",
    "        nir_onset_time, nir_return, nir_globalduration = calculate_signal_duration(\n",
    "            time, nir_smooth_strong, nir_baseline, nir_onset_time, signal_type='NIR', is_low_baseline=is_low_baseline_nir)\n",
    "\n",
    "        # RFP: Determine if it's a low baseline and calculate return time accordingly\n",
    "        rfp_onset_time, rfp_return, rfp_globalduration = calculate_signal_duration(\n",
    "            time, rfp_smooth_strong, rfp_baseline, rfp_onset_time, signal_type='RFP', is_low_baseline=is_low_baseline_rfp)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"GFP: Onset={gfp_onset_time}, Return={gfp_return}, Duration={gfp_globalduration}\")\n",
    "        print(f\"NIR: Onset={nir_onset_time}, Return={nir_return}, Duration={nir_globalduration}\")\n",
    "        print(f\"RFP: Onset={rfp_onset_time}, Return={rfp_return}, Duration={rfp_globalduration}\")\n",
    "\n",
    "        if gfp_onset_time and rfp_onset_time and nir_onset_time:\n",
    "            delay_nir_rfp = rfp_onset_time - nir_onset_time\n",
    "            delay_gfp_rfp = gfp_onset_time - rfp_onset_time\n",
    "            delay_nir_gfp = gfp_onset_time - nir_onset_time   \n",
    "        else:\n",
    "            delay_nir_rfp = delay_gfp_rfp = delay_nir_gfp = None\n",
    "\n",
    "        print(f\"Delay NIR to RFP {delay_nir_rfp}, Delay GFP to RFP {delay_gfp_rfp}, Delay NIR to GFP {delay_nir_gfp}\")\n",
    "                \n",
    "        \n",
    "        \n",
    "        # Step 5: Oscillation Detection and Count (Peaks and Troughs)\n",
    "        # Function to detect peaks and troughs for a given signal\n",
    "\n",
    "        def detect_oscillations(signal, prominence, distance, onset_time=None, return_time=None, lower_threshold=None, upper_threshold=None):\n",
    "            \"\"\"\n",
    "            Detect peaks and troughs in the given signal using specified prominence, distance parameters,\n",
    "            and optional lower and upper thresholds to reduce noise-induced detections near baseline.\n",
    "            Additionally, only consider oscillations between onset and return times.\n",
    "\n",
    "            Parameters:\n",
    "            - signal: The input signal (numpy array)\n",
    "            - prominence: The prominence of the peaks/troughs for detection\n",
    "            - distance: Minimum distance between peaks/troughs\n",
    "            - onset_time: The time to start looking for oscillations (e.g., after the onset)\n",
    "            - return_time: The time to stop looking for oscillations (e.g., before the return time)\n",
    "            - lower_threshold: Lower threshold value to ignore peaks/troughs near the baseline\n",
    "            - upper_threshold: Upper threshold value to ignore peaks/troughs near the baseline\n",
    "\n",
    "            Returns:\n",
    "            - peaks: Indices of the peaks in the signal (between onset and return time)\n",
    "            - troughs: Indices of the troughs in the signal (between onset and return time)\n",
    "            \"\"\"\n",
    "            peaks = find_peaks(signal, prominence=prominence, distance=distance)[0]\n",
    "            troughs = find_peaks(-signal, prominence=prominence, distance=distance)[0]\n",
    "\n",
    "            # Convert onset and return times to indices\n",
    "            if onset_time is not None:\n",
    "                onset_index = (np.abs(time - onset_time)).argmin()\n",
    "            else:\n",
    "                onset_index = 0\n",
    "\n",
    "            if return_time is not None:\n",
    "                return_index = (np.abs(time - return_time)).argmin()\n",
    "            else:\n",
    "                return_index = len(signal)\n",
    "\n",
    "            # Filter peaks and troughs to only include those between onset and return times\n",
    "            peaks = [p for p in peaks if onset_index <= p <= return_index]\n",
    "            troughs = [t for t in troughs if onset_index <= t <= return_index]\n",
    "\n",
    "            # Filter out peaks and troughs that are within the lower and upper thresholds if provided\n",
    "            #if lower_threshold is not None and upper_threshold is not None:\n",
    "            #    peaks = [p for p in peaks if signal[p] < lower_threshold or signal[p] > upper_threshold]\n",
    "            #    troughs = [t for t in troughs if signal[t] < lower_threshold or signal[t] > upper_threshold]\n",
    "\n",
    "            if len(peaks) == 0 or len(troughs) == 0:\n",
    "                print(\"Warning: No valid peaks or troughs detected for the signal.\")\n",
    "\n",
    "            return peaks, troughs\n",
    "\n",
    "        # Detection and Duration Calculation for Each Signal (with onset and return time check)\n",
    "\n",
    "        # Detect peaks and troughs for GFP signal (only between onset and return time)\n",
    "        gfp_peaks, gfp_troughs = detect_oscillations(\n",
    "            gfp_smooth_strong, prominence=gfp_peak_prominence, distance=gfp_peak_distance, onset_time=gfp_onset_time, return_time=gfp_return\n",
    "        )\n",
    "        gfp_oscillations = min(len(gfp_peaks), len(gfp_troughs))  # Each oscillation requires one peak and one trough\n",
    "\n",
    "        # Detect peaks and troughs for RFP signal (only between onset and return time)\n",
    "        rfp_peaks, rfp_troughs = detect_oscillations(\n",
    "            rfp_smooth_strong, prominence=rfp_peak_prominence, distance=rfp_peak_distance, onset_time=rfp_onset_time, return_time=rfp_return\n",
    "        )\n",
    "        rfp_oscillations = min(len(rfp_peaks), len(rfp_troughs))\n",
    "\n",
    "        # Detect peaks and troughs for NIR signal (only between onset and return time)\n",
    "        nir_peaks, nir_troughs = detect_oscillations(\n",
    "            nir_smooth_strong, prominence=nir_peak_prominence, distance=nir_peak_distance, onset_time=nir_onset_time, return_time=nir_return\n",
    "        )\n",
    "        nir_oscillations = min(len(nir_peaks), len(nir_troughs))\n",
    "\n",
    "        # Function to calculate oscillation durations from the derivative of the signal\n",
    "        def calculate_durations(derivative, time, signal_name, onset_time=None, return_time=None):\n",
    "            \"\"\"\n",
    "            Calculate the durations of oscillations based on the changes in the derivative of the signal,\n",
    "            considering only the oscillations between onset and return times.\n",
    "\n",
    "            Parameters:\n",
    "            - derivative: The derivative of the smoothed signal (numpy array)\n",
    "            - time: Time vector corresponding to the signal (numpy array)\n",
    "            - signal_name: Name of the signal being processed (str)\n",
    "            - onset_time: The time to start calculating oscillations (e.g., after the onset)\n",
    "            - return_time: The time to stop calculating oscillations (e.g., before the return time)\n",
    "\n",
    "            Returns:\n",
    "            - signal_durations: List of calculated durations for each oscillation\n",
    "            \"\"\"\n",
    "            # Determine regions where the derivative changes sign (+1 for increase, -1 for decrease)\n",
    "            change_regions = np.sign(derivative)\n",
    "\n",
    "            # Detect changes in regions using np.diff; prepend zero to maintain the length\n",
    "            transitions = np.diff(change_regions, prepend=0)\n",
    "\n",
    "            # Identify indices where transitions occur, indicating peaks or troughs\n",
    "            starts = np.where(transitions != 0)[0]\n",
    "\n",
    "            # Convert onset and return times to indices\n",
    "            if onset_time is not None:\n",
    "                onset_index = (np.abs(time - onset_time)).argmin()\n",
    "            else:\n",
    "                onset_index = 0\n",
    "\n",
    "            if return_time is not None:\n",
    "                return_index = (np.abs(time - return_time)).argmin()\n",
    "            else:\n",
    "                return_index = len(derivative)\n",
    "\n",
    "            # Filter out transitions that are outside the onset to return range\n",
    "            starts = starts[(starts >= onset_index) & (starts <= return_index)]\n",
    "\n",
    "            # Initialize list to store durations of detected oscillations\n",
    "            signal_durations = []\n",
    "\n",
    "            # Loop through the transitions to calculate each oscillation duration\n",
    "            for i in range(len(starts) - 1):\n",
    "                start_idx, end_idx = starts[i], starts[i + 1]\n",
    "\n",
    "                # Validate that indices are within bounds of the time array\n",
    "                if end_idx < len(time):\n",
    "                    duration = int(time[end_idx] - time[start_idx])  # Convert duration to Python int\n",
    "                    signal_durations.append(duration)\n",
    "                else:\n",
    "                    print(f\"Warning: Index {end_idx} is out of bounds for time array of length {len(time)}.\")\n",
    "\n",
    "            return signal_durations\n",
    "\n",
    "        # Compute durations for each signal (considering onset to return time)\n",
    "        durations = {}\n",
    "\n",
    "        # Calculate durations for each signal derivative (GFP, RFP, NIR)\n",
    "        for derivative, name, onset_time, return_time in zip(\n",
    "            [gfp_derivative, rfp_derivative, nir_derivative], \n",
    "            [\"GFP\", \"RFP\", \"NIR\"], \n",
    "            [gfp_onset_time, rfp_onset_time, nir_onset_time],\n",
    "            [gfp_return, rfp_return, nir_return]\n",
    "        ):\n",
    "            durations[name] = calculate_durations(derivative, time, name, onset_time=onset_time, return_time=return_time)\n",
    "\n",
    "    \n",
    "        \n",
    "        # Step 7: Plot curves, smoothed curves and derivative curves\n",
    "        # First plot: Zoomed in on the time range from 120 to 180\n",
    "        plt.figure(figsize=(12, 8))  # Use the same figure size as the first plot\n",
    "        plt.plot(time, gfp, label=\"GFP (Original)\", color='green', alpha=0.5)\n",
    "        plt.plot(time, gfp_smooth, label=\"GFP (Smoothed)\", color='green')\n",
    "        plt.plot(time, gfp_derivative, label=\"GFP Derivative\", color='lime', linestyle='--')        \n",
    "        plt.plot(time, rfp, label=\"RFP (Original)\", color='orange', alpha=0.5)\n",
    "        plt.plot(time, rfp_smooth, label=\"RFP (Smoothed)\", color='orange')\n",
    "        plt.plot(time, rfp_derivative, label=\"RFP Derivative\", color='gold', linestyle='--')\n",
    "        plt.plot(time, nir, label=\"NIR (Original)\", color='darkred', alpha=0.5)\n",
    "        plt.plot(time, nir_smooth, label=\"NIR (Smoothed)\", color='darkred')\n",
    "        plt.plot(time, nir_derivative, label=\"NIR Derivative\", color='red', linestyle='--')   \n",
    "        # Mark detected onsets\n",
    "        if gfp_onset_time: plt.axvline(gfp_onset_time, color='green', linestyle='--', label=\"GFP Onset\")\n",
    "        if rfp_onset_time: plt.axvline(rfp_onset_time, color='orange', linestyle='--', label=\"RFP Onset\")\n",
    "        if nir_onset_time: plt.axvline(nir_onset_time, color='darkred', linestyle='--', label=\"NIR Onset\")        \n",
    "        plt.xlabel(\"Time [sec]\")\n",
    "        plt.ylabel(\"Intensity\")        \n",
    "        plt.legend(loc='upper left', fontsize=6)        \n",
    "        \n",
    "        #Set the x-axis limits to focus on the specified range in seconds\n",
    "        plt.xlim(zoomed_min, zoomed_max)\n",
    "        \n",
    "        # Set the grid for x-axis with major and minor ticks\n",
    "        plt.grid(True, which='major', axis='x', color='lightgrey', linestyle='-', linewidth=0.5)  # Major grid lines\n",
    "        plt.grid(True, which='minor', axis='x', color='lightgrey', linestyle='--', linewidth=0.3)  # Minor grid lines\n",
    "\n",
    "        # Set major ticks (labels) every 10 seconds\n",
    "        plt.gca().xaxis.set_major_locator(MultipleLocator(10))\n",
    "\n",
    "        # Set minor ticks (grid lines) every 2 seconds\n",
    "        plt.gca().xaxis.set_minor_locator(MultipleLocator(2))\n",
    "\n",
    "        # Format minor ticks on the x-axis\n",
    "        plt.tick_params(axis='x', which='minor', length=4, width=0.8, labelsize=8, labelbottom=False)  # Minor ticks, no labels\n",
    "        plt.tick_params(axis='x', which='major', length=6, width=1.2, labelsize=10)  # Major ticks with labels\n",
    "\n",
    "        # Set grid for y-axis\n",
    "        plt.grid(True, which='both', axis='y', color='lightgrey', linestyle='-', linewidth=0.5)\n",
    "        plt.show()\n",
    "                \n",
    "        #Second Plot: Oscillations        \n",
    "        plt.figure(figsize=(12, 8))        \n",
    "        plt.plot(time, gfp, label=\"GFP (Original)\", color='green', alpha=0.5)\n",
    "        plt.plot(time, gfp_smooth_strong, label=\"GFP (Smoothed)\", color='green')\n",
    "        plt.plot(time, gfp_derivative, label=\"GFP Derivative\", color='lime', linestyle='--')        \n",
    "        plt.plot(time, rfp, label=\"RFP (Original)\", color='orange', alpha=0.5)\n",
    "        plt.plot(time, rfp_smooth_strong, label=\"RFP (Smoothed)\", color='orange')\n",
    "        plt.plot(time, rfp_derivative, label=\"RFP Derivative\", color='gold', linestyle='--')        \n",
    "        plt.plot(time, nir, label=\"NIR (Original)\", color='darkred', alpha=0.5)\n",
    "        plt.plot(time, nir_smooth_strong, label=\"NIR (Smoothed)\", color='darkred')\n",
    "        plt.plot(time, nir_derivative, label=\"NIR Derivative\", color='red', linestyle='--')\n",
    "       \n",
    "        #Mark detected peaks with scatter points\n",
    "        for peak in gfp_peaks:\n",
    "            plt.scatter(time[peak], gfp[peak], color='green', zorder=5, label=\"GFP Peak\" if peak == gfp_peaks_derivative[0] else \"\")  # Only label the first peak\n",
    "        for peak in rfp_peaks:\n",
    "            plt.scatter(time[peak], rfp[peak], color='orange', zorder=5, label=\"RFP Peak\" if peak == rfp_peaks_derivative[0] else \"\")  # Only label the first peak\n",
    "        for peak in nir_peaks:\n",
    "            plt.scatter(time[peak], nir[peak], color='darkred', zorder=5, label=\"NIR Peak\" if peak == nir_peaks_derivative[0] else \"\")  # Only label the first peak\n",
    "        #Mark detected troughs with scatter points\n",
    "        for trough in gfp_troughs:\n",
    "            plt.scatter(time[trough], gfp[trough], color='lime', zorder=5, label=\"GFP Trough\" if trough == gfp_troughs[0] else \"\")  # Only label the first trough\n",
    "        for trough in rfp_troughs:\n",
    "            plt.scatter(time[trough], rfp[trough], color='gold', zorder=5, label=\"RFP Trough\" if trough == rfp_troughs[0] else \"\")  # Only label the first trough\n",
    "        for trough in nir_troughs:\n",
    "            plt.scatter(time[trough], nir[trough], color='red', zorder=5, label=\"NIR Trough\" if trough == nir_troughs[0] else \"\")  # Only label the first trough\n",
    "        # Boolean flags to control labeling\n",
    "        gfp_peak_label = True\n",
    "        rfp_peak_label = True\n",
    "        nir_peak_label = True\n",
    "        gfp_trough_label = True\n",
    "        rfp_trough_label = True\n",
    "        nir_trough_label = True\n",
    "        #label and legend\n",
    "        plt.xlabel(\"Time [sec]\", fontsize=10)\n",
    "        plt.ylabel(\"Intensity\", fontsize=10)\n",
    "        plt.legend(loc='upper right', fontsize=6) \n",
    "        # Format the x-axis: label every 5 seconds starting from the first data point\n",
    "        plt.xticks(np.arange(time[0], max(time), 30))  # Set x-ticks every 30 seconds starting from the first time point\n",
    "        plt.grid(True, which='both', axis='x', color='lightgrey', linestyle='-', linewidth=0.2)\n",
    "        plt.grid(True, which='both', axis='y', color='lightgrey', linestyle='-', linewidth=0.2)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.show()\n",
    "                       \n",
    "        # Third plot: Onset and Return + Global length of signal\n",
    "        plt.figure(figsize=(12, 8))  # Use the same figure size as the first plot\n",
    "        # Plot the same data as before\n",
    "        plt.plot(time, gfp, label=\"GFP (Original)\", color='green', alpha=0.5)\n",
    "        plt.plot(time, gfp_smooth_strong, label=\"GFP (Smoothed)\", color='green')\n",
    "        plt.plot(time, rfp, label=\"RFP (Original)\", color='orange', alpha=0.5)\n",
    "        plt.plot(time, rfp_smooth_strong, label=\"RFP (Smoothed)\", color='orange')\n",
    "        plt.plot(time, nir, label=\"NIR (Original)\", color='darkred', alpha=0.5)\n",
    "        plt.plot(time, nir_smooth_strong, label=\"NIR (Smoothed)\", color='darkred')        \n",
    "        # Mark detected onsets and return\n",
    "        if gfp_onset_time: plt.axvline(gfp_onset_time, color='green', linestyle='--', label=\"GFP Onset\")\n",
    "        if rfp_onset_time: plt.axvline(rfp_onset_time, color='orange', linestyle='--', label=\"RFP Onset\")\n",
    "        if nir_onset_time: plt.axvline(nir_onset_time, color='darkred', linestyle='--', label=\"NIR Onset\")        \n",
    "        if gfp_return: plt.axvline(gfp_return, color='lime', linestyle='--', label=\"GFP Return Time\")\n",
    "        if rfp_return: plt.axvline(rfp_return, color='gold', linestyle='--', label=\"NIR Return Time\")\n",
    "        if nir_return: plt.axvline(nir_return, color='red', linestyle='--', label=\"RFP Return Time\")                \n",
    "        plt.xlabel(\"Time [sec]\")\n",
    "        plt.ylabel(\"Intensity\")        \n",
    "        plt.legend(loc='upper right', fontsize=6)        \n",
    "        # Format the x-axis\n",
    "        plt.xticks(np.arange(time[0], max(time), 30))\n",
    "        # Add grid lines\n",
    "        plt.grid(True, which='both', axis='x', color='lightgrey', linestyle='-', linewidth=0.2)\n",
    "        plt.grid(True, which='both', axis='y', color='lightgrey', linestyle='-', linewidth=0.2)\n",
    "        plt.yticks(fontsize=10)        \n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full batch analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "CARMEN Trace Analysis Script â€“ Onset, Return, and Oscillation Detection (Batch)\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "This script performs batch analysis.\n",
    "\n",
    "It is intended for batch processing after parameters have been optimised \n",
    "using a test/trial script. It processes every Excel file in a specified folder and analyses \n",
    "all 3-channel datasets within each file (e.g. columns Câ€“E, Fâ€“H, ...), typically representing\n",
    "individual ROIs or time series replicates.\n",
    "\n",
    "Functionality:\n",
    "- Reads `.xlsm` files from a user-defined folder.\n",
    "- For each dataset (3 adjacent columns), performs:\n",
    "  - Smoothing using Savitzky-Golay filter.\n",
    "  - Onset detection using derivative peaks (via `scipy.signal.find_peaks`).\n",
    "  - Return-to-baseline estimation with threshold- and duration-based logic.\n",
    "  - Oscillation (peak/trough) detection between onset and return.\n",
    "  - Duration calculation for individual oscillatory events based on derivative inflection points.\n",
    "- Generates three summary plots per dataset and saves them as `.png`:\n",
    "  - Zoomed view with onset markers\n",
    "  - Oscillation overview with peak/trough markers\n",
    "  - Global signal summary with onset and return lines\n",
    "- Outputs:\n",
    "  - Excel file with per-dataset results: onset times, return times, durations, oscillation counts\n",
    "  - Text log file with all key parameter settings used in the analysis\n",
    "\n",
    "Assumptions:\n",
    "- Input files are `.xlsm` format with a sheet named 'Time Analysis'.\n",
    "- Time is stored in column 'Protocol Time [sec]' (column B).\n",
    "- Each dataset consists of three adjacent columns (GFP, RFP, NIR), starting from column C onward.\n",
    "- Data may contain NaNs, which are filtered prior to processing.\n",
    "\n",
    "Outputs:\n",
    "- For each input file:\n",
    "  - `<filename>_timing_results.xlsx`: Timing and oscillation results for each dataset\n",
    "  - Three figures per dataset:\n",
    "    - `<filename>_Data_Set_X_zoomed plot.png`\n",
    "    - `<filename>_Data_Set_X_oscillations plot.png`\n",
    "    - `<filename>_Data_Set_X_global plot.png`\n",
    "  - `<filename>_analysis_log.txt`: Parameter documentation for reproducibility\n",
    "\n",
    "Usage:\n",
    "- Adjust parameters (e.g. smoothing window, baseline range, thresholds) in the parameter section.\n",
    "- Set `folder_path` to the desired input directory.\n",
    "- Run the script in a Python environment with the required packages.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if not file_list:\n",
    "    print(f\"No '.xlsm' files found in the folder: {folder_path}\")\n",
    "else:\n",
    "    print(f\"Found {len(file_list)} files: {file_list}\")\n",
    "\n",
    "# Process each file one by one\n",
    "for file_name in file_list:\n",
    "    print(f\"Processing file: {file_name}\") \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # Load data from Excel\n",
    "    df = pd.read_excel(file_path, sheet_name='Time Analysis')\n",
    "    \n",
    "    # Load time in seconds from column B\n",
    "    time_seconds = df['Protocol Time [sec]'].to_numpy()\n",
    "    \n",
    "    data_sets = []  # To store data sets for the current file\n",
    "    results = []  # To store the results for the current file\n",
    "\n",
    "    # Load intensity data from columns C-D-E, F-G-H, etc.\n",
    "    for i in range(0, len(df.columns) - 2, 3):  # Starting from column C\n",
    "        intensity_set = df.iloc[:, 2 + i:5 + i].to_numpy()\n",
    "        \n",
    "        # Filter intensity data and time; Handle NaN values\n",
    "        mask = ~np.isnan(intensity_set).any(axis=1)  # Mask to filter out rows with NaN values\n",
    "        filtered_time = time_seconds[mask]           # Filter time values\n",
    "        filtered_intensity = intensity_set[mask]     # Filter intensity values\n",
    "        \n",
    "        if len(filtered_intensity) > 0:  # Check if the intensity data is not empty\n",
    "            data_sets.append((filtered_time, filtered_intensity))\n",
    "\n",
    "    # Analyze each data set for the current file\n",
    "    for idx, (time, intensity) in enumerate(data_sets):\n",
    "        print(f\"  Processing dataset {idx + 1} in file: {file_name}\")\n",
    "        gfp, rfp, nir = intensity.T  # Split intensity data into gfp, rfp, and nir\n",
    "        \n",
    "        # Step 1: Smooth the data using \n",
    "        gfp_smooth = savgol_filter(gfp, window_length, polyorder)\n",
    "        rfp_smooth = savgol_filter(rfp, window_length, polyorder)\n",
    "        nir_smooth = savgol_filter(nir, window_length, polyorder)\n",
    "        # Stronger smooth the signal to reduce oscillations          \n",
    "        gfp_smooth_strong = savgol_filter(gfp, window_length=window_length_strong, polyorder=polyorder_strong)\n",
    "        rfp_smooth_strong = savgol_filter(rfp, window_length=window_length_strong, polyorder=polyorder_strong)\n",
    "        nir_smooth_strong = savgol_filter(nir, window_length=window_length_strong, polyorder=polyorder_strong)\n",
    "        \n",
    "        # Apply a moving average filter after the Savitzky-Golay filter\n",
    "        #def apply_moving_average(signal, window_size=10):\n",
    "        #    smoothed_signal = pd.Series(signal).rolling(window=window_size, center=True).mean().to_numpy()\n",
    "        #    return smoothed_signal\n",
    "        #gfp_smooth_strong = apply_moving_average(gfp_smooth_strong, window_size=10)\n",
    "        #rfp_smooth_strong = apply_moving_average(rfp_smooth_strong, window_size=10)\n",
    "        #nir_smooth_strong = apply_moving_average(nir_smooth_strong, window_size=10)\n",
    "        \n",
    "        # Step 2: Compute the first derivative\n",
    "        gfp_derivative = np.gradient(gfp_smooth, time)\n",
    "        rfp_derivative = np.gradient(rfp_smooth, time)\n",
    "        nir_derivative = np.gradient(nir_smooth, time)\n",
    "\n",
    "        # Step 3: Detect onset times\n",
    "        # Multiply the derivatives by the respective direction\n",
    "        gfp_adjusted_derivative = gfp_peak_or_trough * gfp_derivative\n",
    "        rfp_adjusted_derivative = rfp_peak_or_trough * rfp_derivative\n",
    "        nir_adjusted_derivative = nir_peak_or_trough * nir_derivative\n",
    "        #Detect peaks in the derivative\n",
    "        gfp_peaks_derivative, _ = find_peaks(gfp_adjusted_derivative, **gfp_params)\n",
    "        rfp_peaks_derivative, _ = find_peaks(rfp_adjusted_derivative, **rfp_params)\n",
    "        nir_peaks_derivative, _ = find_peaks(nir_adjusted_derivative, **nir_params)\n",
    "        # Assign onset times if peaks or troughs were detected        \n",
    "        gfp_onset_time = time[gfp_peaks_derivative[0]] if len(gfp_peaks_derivative) > 0 else None\n",
    "        rfp_onset_time = time[rfp_peaks_derivative[0]] if len(rfp_peaks_derivative) > 0 else None\n",
    "        nir_onset_time = time[nir_peaks_derivative[0]] if len(nir_peaks_derivative) > 0 else None\n",
    "        \n",
    "        # Step 4: Compute return time and global durations\n",
    "        # Function to define the baseline from a specific time range\n",
    "        \n",
    "        def define_baseline(signal, time, baseline_start_time, baseline_end_time):\n",
    "            # Find the indices corresponding to the specified time range\n",
    "            baseline_indices = np.where((time >= baseline_start_time) & (time <= baseline_end_time))[0]\n",
    "\n",
    "            # Ensure that valid indices were found\n",
    "            if len(baseline_indices) == 0:\n",
    "                raise ValueError(\"No valid indices found for baseline calculation.\")\n",
    "            \n",
    "            # Ensure the start time is before the end time\n",
    "            if baseline_start_time >= baseline_end_time:\n",
    "                raise ValueError(\"Baseline start time should be less than baseline end time.\")\n",
    "            \n",
    "            # Check if indices are within the bounds of the signal\n",
    "            if max(baseline_indices) >= len(signal):\n",
    "                raise IndexError(\"Baseline indices are out of bounds of the signal length.\")\n",
    "            \n",
    "            # Calculate and return the mean of the specified baseline range\n",
    "            return np.mean(signal[baseline_indices])\n",
    "        \n",
    "        # Function to calculate signal duration from onset to baseline return\n",
    "        def calculate_signal_duration(time, smoothed_signal, baseline, onset_time, signal_type, \n",
    "                                    is_low_baseline, min_consecutive_points=min_consecutive_points, \n",
    "                                    threshold_percentage=threshold_percentage):    \n",
    "            # Handle the case where onset_time is None, e.g., no onset time could be identified automatically\n",
    "            onset_time_candidate = onset_time\n",
    "            if onset_time_candidate is None:\n",
    "                print(f\"{signal_type} onset_time is None. Using a fixed value of 60 seconds.\")\n",
    "                onset_time_candidate = 360  # Assign default onset_time\n",
    "\n",
    "            # Find the onset index using a tolerance to match the onset time\n",
    "            onset_index = (np.abs(time - onset_time_candidate)).argmin()\n",
    "\n",
    "            # Start searching for the return to baseline at least 30 data points after the onset\n",
    "            start_search_index = onset_index + 30\n",
    "\n",
    "            # Define the lower and upper threshold based on the threshold percentage of the baseline\n",
    "            lower_threshold = baseline * (1 - threshold_percentage)\n",
    "            upper_threshold = baseline * (1 + threshold_percentage)\n",
    "\n",
    "            # Initialize variables to track consecutive points within threshold\n",
    "            consecutive_points = 0\n",
    "            tracked_value_idx = None\n",
    "\n",
    "            # Loop through the signal after the onset to find where the signal returns to baseline range\n",
    "            for idx in range(start_search_index, len(smoothed_signal)):\n",
    "                # Check if the signal is within the range of lower and upper thresholds\n",
    "                if lower_threshold <= smoothed_signal[idx] <= upper_threshold:\n",
    "                    consecutive_points += 1\n",
    "\n",
    "                    # Track maximum or minimum value within the valid range based on `is_low_baseline`\n",
    "                    if is_low_baseline:\n",
    "                        # For GFP and NIR: Track minimum value\n",
    "                        if tracked_value_idx is None or smoothed_signal[idx] < smoothed_signal[tracked_value_idx]:\n",
    "                            tracked_value_idx = idx\n",
    "                    else:\n",
    "                        # For RFP: Track maximum value\n",
    "                        if tracked_value_idx is None or smoothed_signal[idx] > smoothed_signal[tracked_value_idx]:\n",
    "                            tracked_value_idx = idx\n",
    "\n",
    "                else:\n",
    "                    # Reset the consecutive points count if the signal leaves the threshold range\n",
    "                    consecutive_points = 0\n",
    "                    tracked_value_idx = None\n",
    "\n",
    "                # If enough consecutive points are found, consider this a valid return to baseline\n",
    "                if consecutive_points >= min_consecutive_points:\n",
    "                    break  # Exit the loop once a valid return to baseline is found\n",
    "\n",
    "            # Determine return time based on the tracked max or min value index\n",
    "            if tracked_value_idx is not None:\n",
    "                return_time = time[tracked_value_idx]\n",
    "            else:\n",
    "                return_time = np.nan  # If no valid return indices were found\n",
    "\n",
    "            # Calculate the duration from onset to the return to baseline\n",
    "            duration = return_time - onset_time_candidate\n",
    "\n",
    "            # Return the onset time, return time, and calculated duration\n",
    "            return onset_time_candidate, return_time, duration\n",
    "\n",
    "        # Calculate baselines\n",
    "        \n",
    "        gfp_baseline = define_baseline(gfp, time, baseline_start_time, baseline_end_time)\n",
    "        print(f\"GFP baseline calculated for the range {baseline_start_time}s to {baseline_end_time}s: {gfp_baseline}\")\n",
    "\n",
    "        nir_baseline = define_baseline(nir, time, baseline_start_time, baseline_end_time)\n",
    "        print(f\"NIR baseline calculated for the range {baseline_start_time}s to {baseline_end_time}s: {nir_baseline}\")\n",
    "\n",
    "        rfp_baseline = define_baseline(rfp, time, baseline_start_time, baseline_end_time)\n",
    "        print(f\"RFP baseline calculated for the range {baseline_start_time}s to {baseline_end_time}s: {rfp_baseline}\")\n",
    "      \n",
    "        # Determine if the baseline is low or high for each signal\n",
    "        low_baseline_threshold = 20\n",
    "        is_low_baseline_gfp = gfp_baseline < low_baseline_threshold\n",
    "        is_low_baseline_nir = nir_baseline < low_baseline_threshold\n",
    "        is_low_baseline_rfp = rfp_baseline < low_baseline_threshold\n",
    "\n",
    "        # Calculate durations for GFP, RFP, and NIR\n",
    "        # GFP: Determine if it's a low baseline and calculate return time accordingly\n",
    "        gfp_onset_time, gfp_return, gfp_globalduration = calculate_signal_duration(\n",
    "            time, gfp_smooth_strong, gfp_baseline, gfp_onset_time, signal_type='GFP', is_low_baseline=is_low_baseline_gfp)\n",
    "\n",
    "        # NIR: Determine if it's a low baseline and calculate return time accordingly\n",
    "        nir_onset_time, nir_return, nir_globalduration = calculate_signal_duration(\n",
    "            time, nir_smooth_strong, nir_baseline, nir_onset_time, signal_type='NIR', is_low_baseline=is_low_baseline_nir)\n",
    "\n",
    "        # RFP: Determine if it's a low baseline and calculate return time accordingly\n",
    "        rfp_onset_time, rfp_return, rfp_globalduration = calculate_signal_duration(\n",
    "            time, rfp_smooth_strong, rfp_baseline, rfp_onset_time, signal_type='RFP', is_low_baseline=is_low_baseline_rfp)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"GFP: Onset={gfp_onset_time}, Return={gfp_return}, Duration={gfp_globalduration}\")\n",
    "        print(f\"NIR: Onset={nir_onset_time}, Return={nir_return}, Duration={nir_globalduration}\")\n",
    "        print(f\"RFP: Onset={rfp_onset_time}, Return={rfp_return}, Duration={rfp_globalduration}\")\n",
    "\n",
    "        if gfp_onset_time and rfp_onset_time and nir_onset_time:\n",
    "            delay_nir_rfp = rfp_onset_time - nir_onset_time\n",
    "            delay_gfp_rfp = gfp_onset_time - rfp_onset_time\n",
    "            delay_nir_gfp = gfp_onset_time - nir_onset_time   \n",
    "        else:\n",
    "            delay_nir_rfp = delay_gfp_rfp = delay_nir_gfp = None\n",
    "\n",
    "        print(f\"Delay NIR to RFP {delay_nir_rfp}, Delay GFP to RFP {delay_gfp_rfp}, Delay NIR to GFP {delay_nir_gfp}\")\n",
    "                \n",
    "        # Step 5: Oscillation Detection and Count (Peaks and Troughs)\n",
    "        # Function to detect peaks and troughs for a given signal\n",
    "\n",
    "        def detect_oscillations(signal, prominence, distance, onset_time=None, return_time=None, lower_threshold=None, upper_threshold=None):\n",
    "            \"\"\"\n",
    "            Detect peaks and troughs in the given signal using specified prominence, distance parameters,\n",
    "            and optional lower and upper thresholds to reduce noise-induced detections near baseline.\n",
    "            Additionally, only consider oscillations between onset and return times.\n",
    "\n",
    "            Parameters:\n",
    "            - signal: The input signal (numpy array)\n",
    "            - prominence: The prominence of the peaks/troughs for detection\n",
    "            - distance: Minimum distance between peaks/troughs\n",
    "            - onset_time: The time to start looking for oscillations (e.g., after the onset)\n",
    "            - return_time: The time to stop looking for oscillations (e.g., before the return time)\n",
    "            - lower_threshold: Lower threshold value to ignore peaks/troughs near the baseline\n",
    "            - upper_threshold: Upper threshold value to ignore peaks/troughs near the baseline\n",
    "\n",
    "            Returns:\n",
    "            - peaks: Indices of the peaks in the signal (between onset and return time)\n",
    "            - troughs: Indices of the troughs in the signal (between onset and return time)\n",
    "            \"\"\"\n",
    "            peaks = find_peaks(signal, prominence=prominence, distance=distance)[0]\n",
    "            troughs = find_peaks(-signal, prominence=prominence, distance=distance)[0]\n",
    "\n",
    "            # Convert onset and return times to indices\n",
    "            if onset_time is not None:\n",
    "                onset_index = (np.abs(time - onset_time)).argmin()\n",
    "            else:\n",
    "                onset_index = 0\n",
    "\n",
    "            if return_time is not None:\n",
    "                return_index = (np.abs(time - return_time)).argmin()\n",
    "            else:\n",
    "                return_index = len(signal)\n",
    "\n",
    "            # Filter peaks and troughs to only include those between onset and return times\n",
    "            peaks = [p for p in peaks if onset_index <= p <= return_index]\n",
    "            troughs = [t for t in troughs if onset_index <= t <= return_index]\n",
    "\n",
    "            # Filter out peaks and troughs that are within the lower and upper thresholds if provided\n",
    "            #if lower_threshold is not None and upper_threshold is not None:\n",
    "            #    peaks = [p for p in peaks if signal[p] < lower_threshold or signal[p] > upper_threshold]\n",
    "            #    troughs = [t for t in troughs if signal[t] < lower_threshold or signal[t] > upper_threshold]\n",
    "\n",
    "            if len(peaks) == 0 or len(troughs) == 0:\n",
    "                print(\"Warning: No valid peaks or troughs detected for the signal.\")\n",
    "\n",
    "            return peaks, troughs\n",
    "\n",
    "        # Detection and Duration Calculation for Each Signal (with onset and return time check)\n",
    "\n",
    "        # Detect peaks and troughs for GFP signal (only between onset and return time)\n",
    "        gfp_peaks, gfp_troughs = detect_oscillations(\n",
    "            gfp_smooth_strong, prominence=gfp_peak_prominence, distance=gfp_peak_distance, onset_time=gfp_onset_time, return_time=gfp_return\n",
    "        )\n",
    "        gfp_oscillations = min(len(gfp_peaks), len(gfp_troughs))  # Each oscillation requires one peak and one trough\n",
    "\n",
    "        # Detect peaks and troughs for RFP signal (only between onset and return time)\n",
    "        rfp_peaks, rfp_troughs = detect_oscillations(\n",
    "            rfp_smooth_strong, prominence=rfp_peak_prominence, distance=rfp_peak_distance, onset_time=rfp_onset_time, return_time=rfp_return\n",
    "        )\n",
    "        rfp_oscillations = min(len(rfp_peaks), len(rfp_troughs))\n",
    "\n",
    "        # Detect peaks and troughs for NIR signal (only between onset and return time)\n",
    "        nir_peaks, nir_troughs = detect_oscillations(\n",
    "            nir_smooth_strong, prominence=nir_peak_prominence, distance=nir_peak_distance, onset_time=nir_onset_time, return_time=nir_return\n",
    "        )\n",
    "        nir_oscillations = min(len(nir_peaks), len(nir_troughs))\n",
    "\n",
    "        # Function to calculate oscillation durations from the derivative of the signal\n",
    "        def calculate_durations(derivative, time, signal_name, onset_time=None, return_time=None):\n",
    "            \"\"\"\n",
    "            Calculate the durations of oscillations based on the changes in the derivative of the signal,\n",
    "            considering only the oscillations between onset and return times.\n",
    "\n",
    "            Parameters:\n",
    "            - derivative: The derivative of the smoothed signal (numpy array)\n",
    "            - time: Time vector corresponding to the signal (numpy array)\n",
    "            - signal_name: Name of the signal being processed (str)\n",
    "            - onset_time: The time to start calculating oscillations (e.g., after the onset)\n",
    "            - return_time: The time to stop calculating oscillations (e.g., before the return time)\n",
    "\n",
    "            Returns:\n",
    "            - signal_durations: List of calculated durations for each oscillation\n",
    "            \"\"\"\n",
    "            # Determine regions where the derivative changes sign (+1 for increase, -1 for decrease)\n",
    "            change_regions = np.sign(derivative)\n",
    "\n",
    "            # Detect changes in regions using np.diff; prepend zero to maintain the length\n",
    "            transitions = np.diff(change_regions, prepend=0)\n",
    "\n",
    "            # Identify indices where transitions occur, indicating peaks or troughs\n",
    "            starts = np.where(transitions != 0)[0]\n",
    "\n",
    "            # Convert onset and return times to indices\n",
    "            if onset_time is not None:\n",
    "                onset_index = (np.abs(time - onset_time)).argmin()\n",
    "            else:\n",
    "                onset_index = 0\n",
    "\n",
    "            if return_time is not None:\n",
    "                return_index = (np.abs(time - return_time)).argmin()\n",
    "            else:\n",
    "                return_index = len(derivative)\n",
    "\n",
    "            # Filter out transitions that are outside the onset to return range\n",
    "            starts = starts[(starts >= onset_index) & (starts <= return_index)]\n",
    "\n",
    "            # Initialize list to store durations of detected oscillations\n",
    "            signal_durations = []\n",
    "\n",
    "            # Loop through the transitions to calculate each oscillation duration\n",
    "            for i in range(len(starts) - 1):\n",
    "                start_idx, end_idx = starts[i], starts[i + 1]\n",
    "\n",
    "                # Validate that indices are within bounds of the time array\n",
    "                if end_idx < len(time):\n",
    "                    duration = int(time[end_idx] - time[start_idx])  # Convert duration to Python int\n",
    "                    signal_durations.append(duration)\n",
    "                else:\n",
    "                    print(f\"Warning: Index {end_idx} is out of bounds for time array of length {len(time)}.\")\n",
    "\n",
    "            return signal_durations\n",
    "\n",
    "        # Compute durations for each signal (considering onset to return time)\n",
    "        durations = {}\n",
    "\n",
    "        # Calculate durations for each signal derivative (GFP, RFP, NIR)\n",
    "        for derivative, name, onset_time, return_time in zip(\n",
    "            [gfp_derivative, rfp_derivative, nir_derivative], \n",
    "            [\"GFP\", \"RFP\", \"NIR\"], \n",
    "            [gfp_onset_time, rfp_onset_time, nir_onset_time],\n",
    "            [gfp_return, rfp_return, nir_return]\n",
    "        ):\n",
    "            durations[name] = calculate_durations(derivative, time, name, onset_time=onset_time, return_time=return_time)\n",
    "        \n",
    "        \n",
    "        # Step 6: Append results\n",
    "        results.append([\n",
    "            idx + 1,\n",
    "            gfp_onset_time, rfp_onset_time, nir_onset_time,\n",
    "            gfp_return, rfp_return, nir_return, \n",
    "            gfp_oscillations, rfp_oscillations, nir_oscillations,\n",
    "            durations.get(\"GFP\", []), durations.get(\"RFP\", []), durations.get(\"NIR\", []), \n",
    "            gfp_globalduration, rfp_globalduration, nir_globalduration\n",
    "        ])\n",
    "        # could also directly append: delay_nir_rfp, delay_gfp_rfp, delay_nir_gfp,\n",
    "        # Step 7: Plot curves, smoothed curves and derivative curves\n",
    "        # First plot: Zoomed in on the time range from 120 to 180\n",
    "        plt.figure(figsize=(12, 8))  # Use the same figure size as the first plot\n",
    "        plt.plot(time, gfp, label=\"GFP (Original)\", color='green', alpha=0.5)\n",
    "        plt.plot(time, gfp_smooth, label=\"GFP (Smoothed)\", color='green')\n",
    "        plt.plot(time, gfp_derivative, label=\"GFP Derivative\", color='lime', linestyle='--')        \n",
    "        plt.plot(time, rfp, label=\"RFP (Original)\", color='orange', alpha=0.5)\n",
    "        plt.plot(time, rfp_smooth, label=\"RFP (Smoothed)\", color='orange')\n",
    "        plt.plot(time, rfp_derivative, label=\"RFP Derivative\", color='gold', linestyle='--')\n",
    "        plt.plot(time, nir, label=\"NIR (Original)\", color='darkred', alpha=0.5)\n",
    "        plt.plot(time, nir_smooth, label=\"NIR (Smoothed)\", color='darkred')\n",
    "        plt.plot(time, nir_derivative, label=\"NIR Derivative\", color='red', linestyle='--')   \n",
    "        # Mark detected onsets\n",
    "        if gfp_onset_time: plt.axvline(gfp_onset_time, color='green', linestyle='--', label=\"GFP Onset\")\n",
    "        if rfp_onset_time: plt.axvline(rfp_onset_time, color='orange', linestyle='--', label=\"RFP Onset\")\n",
    "        if nir_onset_time: plt.axvline(nir_onset_time, color='darkred', linestyle='--', label=\"NIR Onset\")        \n",
    "        plt.xlabel(\"Time [sec]\")\n",
    "        plt.ylabel(\"Intensity\")        \n",
    "        plt.legend(loc='upper left', fontsize=6)        \n",
    "        \n",
    "        #Set the x-axis limits to focus on the specified range in seconds\n",
    "        plt.xlim(zoomed_min, zoomed_max)\n",
    "        \n",
    "        # Set the grid for x-axis with major and minor ticks\n",
    "        plt.grid(True, which='major', axis='x', color='lightgrey', linestyle='-', linewidth=0.5)  # Major grid lines\n",
    "        plt.grid(True, which='minor', axis='x', color='lightgrey', linestyle='--', linewidth=0.3)  # Minor grid lines\n",
    "\n",
    "        # Set major ticks (labels) every 10 seconds\n",
    "        plt.gca().xaxis.set_major_locator(MultipleLocator(10))\n",
    "\n",
    "        # Set minor ticks (grid lines) every 2 seconds\n",
    "        plt.gca().xaxis.set_minor_locator(MultipleLocator(2))\n",
    "\n",
    "        # Format minor ticks on the x-axis\n",
    "        plt.tick_params(axis='x', which='minor', length=4, width=0.8, labelsize=8, labelbottom=False)  # Minor ticks, no labels\n",
    "        plt.tick_params(axis='x', which='major', length=6, width=1.2, labelsize=10)  # Major ticks with labels\n",
    "\n",
    "        # Set grid for y-axis\n",
    "        plt.grid(True, which='both', axis='y', color='lightgrey', linestyle='-', linewidth=0.5)\n",
    "\n",
    "\n",
    "        # Save the plot as PNG file\n",
    "        plot1_filename = os.path.join(folder_path, f\"{os.path.splitext(file_name)[0]}_Data_Set_{idx + 1}_zoomed plot.png\")\n",
    "        plt.title(f\"Signal Analysis - {os.path.splitext(file_name)[0]}_Data_Set_{idx + 1}\")\n",
    "        plt.savefig(plot1_filename)\n",
    "        plt.close()\n",
    "        #plt.show()\n",
    "                \n",
    "        #Second Plot: Oscillations        \n",
    "        plt.figure(figsize=(12, 8))        \n",
    "        plt.plot(time, gfp, label=\"GFP (Original)\", color='green', alpha=0.5)\n",
    "        plt.plot(time, gfp_smooth_strong, label=\"GFP (Smoothed)\", color='green')\n",
    "        plt.plot(time, gfp_derivative, label=\"GFP Derivative\", color='lime', linestyle='--')        \n",
    "        plt.plot(time, rfp, label=\"RFP (Original)\", color='orange', alpha=0.5)\n",
    "        plt.plot(time, rfp_smooth_strong, label=\"RFP (Smoothed)\", color='orange')\n",
    "        plt.plot(time, rfp_derivative, label=\"RFP Derivative\", color='gold', linestyle='--')        \n",
    "        plt.plot(time, nir, label=\"NIR (Original)\", color='darkred', alpha=0.5)\n",
    "        plt.plot(time, nir_smooth_strong, label=\"NIR (Smoothed)\", color='darkred')\n",
    "        plt.plot(time, nir_derivative, label=\"NIR Derivative\", color='red', linestyle='--')\n",
    "        # Mark detected onsets and return\n",
    "        #if gfp_onset_time: plt.axvline(gfp_onset_time, color='green', linestyle='--', label=\"GFP Onset\")\n",
    "        #if rfp_onset_time: plt.axvline(rfp_onset_time, color='orange', linestyle='--', label=\"RFP Onset\")\n",
    "        #if nir_onset_time: plt.axvline(nir_onset_time, color='darkred', linestyle='--', label=\"NIR Onset\")\n",
    "        #if gfp_return: plt.axvline(gfp_return, color='lime', linestyle='--', label=\"GFP Return Time\")\n",
    "        #if rfp_return: plt.axvline(rfp_return, color='gold', linestyle='--', label=\"RFP Return Time\")\n",
    "        #if nir_return: plt.axvline(nir_return, color='red', linestyle='--', label=\"NIR Return Time\")\n",
    "        #Mark detected peaks with scatter points\n",
    "        for peak in gfp_peaks:\n",
    "            plt.scatter(time[peak], gfp[peak], color='green', zorder=5, label=\"GFP Peak\" if peak == gfp_peaks[0] else \"\")  # Only label the first peak\n",
    "        for peak in rfp_peaks:\n",
    "            plt.scatter(time[peak], rfp[peak], color='orange', zorder=5, label=\"RFP Peak\" if peak == rfp_peaks[0] else \"\")  # Only label the first peak\n",
    "        for peak in nir_peaks:\n",
    "            plt.scatter(time[peak], nir[peak], color='darkred', zorder=5, label=\"NIR Peak\" if peak == nir_peaks[0] else \"\")  # Only label the first peak\n",
    "        #Mark detected troughs with scatter points\n",
    "        for trough in gfp_troughs:\n",
    "            plt.scatter(time[trough], gfp[trough], color='lime', zorder=5, label=\"GFP Trough\" if trough == gfp_troughs[0] else \"\")  # Only label the first trough\n",
    "        for trough in rfp_troughs:\n",
    "            plt.scatter(time[trough], rfp[trough], color='gold', zorder=5, label=\"RFP Trough\" if trough == rfp_troughs[0] else \"\")  # Only label the first trough\n",
    "        for trough in nir_troughs:\n",
    "            plt.scatter(time[trough], nir[trough], color='red', zorder=5, label=\"NIR Trough\" if trough == nir_troughs[0] else \"\")  # Only label the first trough\n",
    "        # Boolean flags to control labeling\n",
    "        gfp_peak_label = True\n",
    "        rfp_peak_label = True\n",
    "        nir_peak_label = True\n",
    "        gfp_trough_label = True\n",
    "        rfp_trough_label = True\n",
    "        nir_trough_label = True\n",
    "        #label and legend\n",
    "        plt.xlabel(\"Time [sec]\", fontsize=10)\n",
    "        plt.ylabel(\"Intensity\", fontsize=10)\n",
    "        plt.legend(loc='upper right', fontsize=6) \n",
    "        # Format the x-axis: label every 5 seconds starting from the first data point\n",
    "        plt.xticks(np.arange(time[0], max(time), 30))  # Set x-ticks every 30 seconds starting from the first time point\n",
    "        plt.grid(True, which='both', axis='x', color='lightgrey', linestyle='-', linewidth=0.2)\n",
    "        plt.grid(True, which='both', axis='y', color='lightgrey', linestyle='-', linewidth=0.2)\n",
    "        plt.yticks(fontsize=10)\n",
    "        # Save the plot as PNG file\n",
    "        plot2_filename = os.path.join(folder_path, f\"{os.path.splitext(file_name)[0]}_Data_Set_{idx + 1}_oscillations plot.png\")\n",
    "        plt.title(f\"Signal Analysis - {os.path.splitext(file_name)[0]}_Data_Set_{idx + 1}\")\n",
    "        plt.savefig(plot2_filename)\n",
    "        plt.close()\n",
    "        #plt.show()\n",
    "                       \n",
    "        # Third plot: Onset and Return + Global length of signal\n",
    "        plt.figure(figsize=(12, 8))  # Use the same figure size as the first plot\n",
    "        # Plot the same data as before        \n",
    "        plt.plot(time, gfp, label=\"GFP (Original)\", color='green', alpha=0.5)\n",
    "        plt.plot(time, gfp_smooth_strong, label=\"GFP (Smoothed)\", color='green')\n",
    "        plt.plot(time, gfp_derivative, label=\"GFP Derivative\", color='lime', linestyle='--')        \n",
    "        plt.plot(time, rfp, label=\"RFP (Original)\", color='orange', alpha=0.5)\n",
    "        plt.plot(time, rfp_smooth_strong, label=\"RFP (Smoothed)\", color='orange')\n",
    "        plt.plot(time, rfp_derivative, label=\"RFP Derivative\", color='gold', linestyle='--')        \n",
    "        plt.plot(time, nir, label=\"NIR (Original)\", color='darkred', alpha=0.5)\n",
    "        plt.plot(time, nir_smooth_strong, label=\"NIR (Smoothed)\", color='darkred')\n",
    "        plt.plot(time, nir_derivative, label=\"NIR Derivative\", color='red', linestyle='--')\n",
    "        \n",
    "        # Mark detected onsets and return\n",
    "        if gfp_onset_time: plt.axvline(gfp_onset_time, color='green', linestyle='--', label=\"GFP Onset\")\n",
    "        if rfp_onset_time: plt.axvline(rfp_onset_time, color='orange', linestyle='--', label=\"RFP Onset\")\n",
    "        if nir_onset_time: plt.axvline(nir_onset_time, color='darkred', linestyle='--', label=\"NIR Onset\")        \n",
    "        if gfp_return: plt.axvline(gfp_return, color='lime', linestyle='--', label=\"GFP Return Time\")\n",
    "        if rfp_return: plt.axvline(rfp_return, color='gold', linestyle='--', label=\"NIR Return Time\")\n",
    "        if nir_return: plt.axvline(nir_return, color='red', linestyle='--', label=\"RFP Return Time\")                \n",
    "        plt.xlabel(\"Time [sec]\")\n",
    "        plt.ylabel(\"Intensity\")        \n",
    "        plt.legend(loc='upper right', fontsize=6)        \n",
    "        # Format the x-axis\n",
    "        plt.xticks(np.arange(time[0], max(time), 30))\n",
    "        # Add grid lines\n",
    "        plt.grid(True, which='both', axis='x', color='lightgrey', linestyle='-', linewidth=0.2)\n",
    "        plt.grid(True, which='both', axis='y', color='lightgrey', linestyle='-', linewidth=0.2)\n",
    "        plt.yticks(fontsize=10)        \n",
    "        # Save the plot as PNG file\n",
    "        plot3_filename = os.path.join(folder_path, f\"{os.path.splitext(file_name)[0]}_Data_Set_{idx + 1}_global plot.png\")\n",
    "        plt.title(f\"Signal Analysis - {os.path.splitext(file_name)[0]}_Data_Set_{idx + 1}\")\n",
    "        plt.savefig(plot3_filename)\n",
    "        plt.close()\n",
    "        #plt.show()\n",
    "      \n",
    "    # Save results to Excel (update headers to include new metrics)\n",
    "    output_file_path = os.path.join(folder_path, f\"{os.path.splitext(file_name)[0]}_timing_results.xlsx\")\n",
    "    results_df = pd.DataFrame(results, columns=[\n",
    "        \"Data Set\", \"GFP Onset Time\", \"RFP Onset Time\", \"NIR Onset Time\",\n",
    "        \"GFP Return Time\", \"RFP Return Time\", \"NIR Return Time\",\n",
    "        \"GFP Oscillations\", \"RFP Oscillations\", \"NIR Oscillations\",\n",
    "        \"GFP Peak Durations\", \"RFP Peak Durations\", \"NIR Peak Durations\",\n",
    "        \"GFP Global Duration\", \"RFP Global Duration\", \"NIR Global Duration\"\n",
    "    ])\n",
    "    #\"Delay RFP-NIR\", \"Delay GFP-RFP\", \"Delay GFP-NIR\",\n",
    "    results_df.to_excel(output_file_path, index=False)\n",
    "    print(f\"Results saved to {output_file_path}\")\n",
    "\n",
    "# Define the log file path\n",
    "log_file_path = os.path.join(folder_path, f\"{os.path.splitext(file_name)[0]}_analysis_log.txt\")\n",
    "\n",
    "# Function to log parameters to a file\n",
    "def log_parameters_to_file(file_path):\n",
    "    # Open the file in write mode to overwrite its content\n",
    "    with open(file_path, 'w') as file:\n",
    "        # Write constants for smoothing with Savitzky-Golay filter\n",
    "        file.write(f\"window_length = {window_length}\\n\")\n",
    "        file.write(f\"polyorder = {polyorder}\\n\")\n",
    "        file.write(f\"window_length_strong = {window_length_strong}\\n\")\n",
    "        file.write(f\"polyorder_strong = {polyorder_strong}\\n\")\n",
    "\n",
    "        # Write threshold and min consecutive points for return calculation\n",
    "        file.write(f\"threshold_percentage = {threshold_percentage}\\n\")\n",
    "        file.write(f\"min_consecutive_points = {min_consecutive_points}\\n\")\n",
    "\n",
    "        # Write baseline time range\n",
    "        file.write(f\"baseline_start_time = {baseline_start_time}\\n\")\n",
    "        file.write(f\"baseline_end_time = {baseline_end_time}\\n\")\n",
    "\n",
    "        # Write parameters for onset peak detection\n",
    "        file.write(f\"gfp_params = {gfp_params}\\n\")\n",
    "        file.write(f\"rfp_params = {rfp_params}\\n\")\n",
    "        file.write(f\"nir_params = {nir_params}\\n\")\n",
    "\n",
    "        # Write oscillation detection parameters\n",
    "        file.write(f\"gfp_peak_prominence = {gfp_peak_prominence}\\n\")\n",
    "        file.write(f\"gfp_peak_distance = {gfp_peak_distance}\\n\")\n",
    "        file.write(f\"rfp_peak_prominence = {rfp_peak_prominence}\\n\")\n",
    "        file.write(f\"rfp_peak_distance = {rfp_peak_distance}\\n\")\n",
    "        file.write(f\"nir_peak_prominence = {nir_peak_prominence}\\n\")\n",
    "        file.write(f\"nir_peak_distance = {nir_peak_distance}\\n\")\n",
    "\n",
    "# Call the function to log parameters\n",
    "log_parameters_to_file(log_file_path)\n",
    "print(f\"Variables and constants logged to {log_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
